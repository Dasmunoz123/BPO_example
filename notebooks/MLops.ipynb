{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file = \"../2023-10-31 5_50pm.csv\"\n",
    "target_columns = ['CREATED_AT','AHT_LS', 'SURVEY_RATING', 'FRT_QUEUE', 'SLA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name, column_names):\n",
    "    for chunk in pd.read_csv(filepath_or_buffer=file_name, chunksize=10e6, low_memory=False, usecols=column_names): # type: ignore\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# For building DataFrame chunk by chunk\\ndata = pd.DataFrame()\\nfor df_chunk in read_csv(file_name=file, column_names=target_columns):\\n    df_chunk = df_chunk.dropna()\\n    data = pd.concat(objs=[data,df_chunk])\\n    \\n    # checking data increase\\n    data_size = sys.getsizeof(data)             # Gives results in bytes\\n    data_size = data_size * (1/1024)            # Calculate memory in kb\\n    if data_size > 10e6:                        # Fails if the data requires more than 10 GB in memory\\n        print(f\"Datos escalando en memoria\")\\n        sys.exit()\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# For building DataFrame chunk by chunk\n",
    "data = pd.DataFrame()\n",
    "for df_chunk in read_csv(file_name=file, column_names=target_columns):\n",
    "    df_chunk = df_chunk.dropna()\n",
    "    data = pd.concat(objs=[data,df_chunk])\n",
    "    \n",
    "    # checking data increase\n",
    "    data_size = sys.getsizeof(data)             # Gives results in bytes\n",
    "    data_size = data_size * (1/1024)            # Calculate memory in kb\n",
    "    if data_size > 10e6:                        # Fails if the data requires more than 10 GB in memory\n",
    "        print(f\"Datos escalando en memoria\")\n",
    "        sys.exit()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filepath_or_buffer=file, usecols=target_columns)\n",
    "data = data.dropna()\n",
    "data_size = sys.getsizeof(data)       # gives results in bytes\n",
    "data_size = data_size * (1/1024)\n",
    "print(f\"Dataframe size : {data_size/1000} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms for raw data\n",
    "data.hist(figsize=(7,7))\n",
    "\n",
    "print(data['AHT_LS'].max())\n",
    "print(data['AHT_LS'].min())\n",
    "print(data['AHT_LS'].mean())\n",
    "print(data['AHT_LS'].median())\n",
    "print(data['AHT_LS'].std())\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(data['FRT_QUEUE'].max())\n",
    "print(data['FRT_QUEUE'].min())\n",
    "print(data['FRT_QUEUE'].mean())\n",
    "print(data['FRT_QUEUE'].median())\n",
    "print(data['FRT_QUEUE'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CREATED_AT'] = data['CREATED_AT'].apply(func= lambda x : pd.to_datetime(x))\n",
    "data['CREATED_AT'] = data['CREATED_AT'].dt.tz_localize(tz=None)\n",
    "data['CREATED_AT_YEAR'] = data['CREATED_AT'].dt.year\n",
    "data['CREATED_AT_MONTH'] = data['CREATED_AT'].dt.month\n",
    "data['CREATED_AT_HOUR'] = data['CREATED_AT'].dt.hour\n",
    "\n",
    "data = data.sort_values(by=['CREATED_AT'], ascending=True)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unskeew data\n",
    "data['AHT_LS'] = np.log(data['AHT_LS'] + 1)\n",
    "data['FRT_QUEUE'] = np.log(data['FRT_QUEUE'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['CREATED_AT_HOUR', 'CREATED_AT_MONTH', 'AHT_LS', 'SURVEY_RATING', 'FRT_QUEUE', 'SLA']\n",
    "# Histogram for data distribution\n",
    "data[target_cols].hist(figsize=(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap with the correlations between data\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(data[target_cols].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data=data[target_cols], hue=None, palette=\"husl\", size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For problem #1\n",
    "'''\n",
    "Se ha observado una variabilidad en el tiempo promedio de manejo (AHT) de las interacciones con los clientes. \n",
    "El objetivo es entender las variables que más influyen en el AHT y construir un modelo explicativo que ayude a \n",
    "identificar áreas de mejora y optimización.\n",
    "\n",
    "# Predict AHT_LS\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Selecting variables and splitting dataset -- stage\n",
    "X = data.drop(labels=['AHT_LS','CREATED_AT', 'CREATED_AT_YEAR'], axis=1)\n",
    "y = data['AHT_LS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=0)\n",
    "\n",
    "train_data = X_train.join(y_train)\n",
    "train_data.head()\n",
    "\n",
    "# Scaling dataset -- stage\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "standart_scaler_X = MinMaxScaler()\n",
    "standart_scaler_X.fit(X=X_train)\n",
    "X_train_scaled = standart_scaler_X.transform(X=X_train)\n",
    "X_test_scaled = standart_scaler_X.transform(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "forest_regresor = RandomForestRegressor()\n",
    "forest_regresor.fit(X = X_train_scaled, y = y_train)\n",
    "score_F1 = forest_regresor.score(X = X_train_scaled, y = y_train)\n",
    "score_F2 = forest_regresor.score(X = X_test_scaled, y = y_test)\n",
    "print(f\"The mean accuracy for RandomForest {round(score_F1,3)} -- {round(score_F2,3)}\")\n",
    "\n",
    "\n",
    "knn_regresor = KNeighborsRegressor()\n",
    "knn_regresor.fit(X = X_train_scaled, y = y_train)\n",
    "score_F1 = knn_regresor.score(X = X_train_scaled, y = y_train)\n",
    "score_F2 = knn_regresor.score(X = X_test_scaled, y = y_test)\n",
    "print(f\"The mean accuracy for Knn {round(score_F1,3)} -- {round(score_F2,3)}\")\n",
    "\n",
    "\n",
    "lin_regresor = LinearRegression()\n",
    "lin_regresor.fit(X = X_train_scaled, y = y_train)\n",
    "score_F1 = lin_regresor.score(X = X_train_scaled, y = y_train)\n",
    "score_F2 = lin_regresor.score(X = X_test_scaled, y = y_test)\n",
    "print(f\"The mean accuracy for linreg {round(score_F1,3)} -- {round(score_F2,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "plt.plot(y_train, label='y_true')\n",
    "plt.plot(forest_regresor.predict(X=X_train_scaled), label='y_forest')\n",
    "plt.plot(knn_regresor.predict(X=X_train_scaled), label='y_knn')\n",
    "plt.plot(lin_regresor.predict(X=X_train_scaled), label='y_linreg')\n",
    "plt.legend()\n",
    "plt.ylabel(ylabel='ln(AHT_LS) + 1')\n",
    "plt.title('Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "plt.plot(y_test, label='y_true')\n",
    "plt.plot(forest_regresor.predict(X=X_test_scaled), label='y_forest')\n",
    "plt.plot(knn_regresor.predict(X=X_test_scaled), label='y_knn')\n",
    "plt.plot(lin_regresor.predict(X=X_test_scaled), label='y_linreg')\n",
    "plt.legend()\n",
    "plt.ylabel(ylabel='ln(AHT_LS) + 1')\n",
    "plt.title('Testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For problem #2\n",
    "'''\n",
    "El CSAT puede variar según diversos factores, como la calidad de la entrega, la precisión del pedido, \n",
    "la velocidad de entrega y la interacción del usuario con la aplicación. Predecir la satisfacción del cliente \n",
    "permitiría intervenir proactivamente en situaciones que podrían afectar negativamente la experiencia del usuario, \n",
    "por ello se necesita un modelo de Forecasting para predecir el CSAT. \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
